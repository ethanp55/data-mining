{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore the warning messages from sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER CODE PROVIDED ON LS\n",
    "\n",
    "# Converts an int 0 < int_to_code < 2^code_length-1 to a bool array of length code_length\n",
    "def int2bin(int_to_code, code_length):\n",
    "    bin_eq = []\n",
    "    \n",
    "    while int_to_code != 0:\n",
    "        n_div_2 = divmod(int_to_code, 2)\n",
    "        bin_eq.insert(0, n_div_2[1])\n",
    "        int_to_code = n_div_2[0]\n",
    "\n",
    "    while len(bin_eq) != code_length:\n",
    "        bin_eq.insert(0, 0)\n",
    "\n",
    "    return bin_eq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 1, 0],\n",
       " [0, 0, 1, 1],\n",
       " [0, 1, 0, 0],\n",
       " [0, 1, 0, 1],\n",
       " [0, 1, 1, 0],\n",
       " [0, 1, 1, 1],\n",
       " [1, 0, 0, 0],\n",
       " [1, 0, 0, 1],\n",
       " [1, 0, 1, 0],\n",
       " [1, 0, 1, 1],\n",
       " [1, 1, 0, 0],\n",
       " [1, 1, 0, 1],\n",
       " [1, 1, 1, 0],\n",
       " [1, 1, 1, 1]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HELPER CODE FOR GENERATING THE TRAINING SET\n",
    "def all_bits(n):\n",
    "    if n: yield from (bits + [bit] for bits in all_bits(n - 1) for bit in [0, 1])\n",
    "    else: yield []\n",
    "\n",
    "print('Example:')\n",
    "list(all_bits(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performances:\n",
      "dummy: 0\n",
      "NB: 0\n",
      "MLP: 0\n",
      "DT: 0\n"
     ]
    }
   ],
   "source": [
    "# Testing NFL in Boolean X-space\n",
    "\n",
    "# Set up the space\n",
    "num_features = 3\n",
    "num_instances = 2 ** num_features\n",
    "num_tasks = 2 ** num_instances\n",
    "\n",
    "# Training data\n",
    "x = list(all_bits(num_features))\n",
    "\n",
    "# Random state\n",
    "RANDOM_STATE = 5\n",
    "\n",
    "# Classifiers\n",
    "classifiers = {'dummy': DummyClassifier(strategy='most_frequent', random_state=RANDOM_STATE),\n",
    "               'NB': GaussianNB(),\n",
    "               'MLP': MLPClassifier(random_state=RANDOM_STATE), \n",
    "               'DT': DecisionTreeClassifier(random_state=RANDOM_STATE)}\n",
    "\n",
    "performances = {}\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    # Generalization performance\n",
    "    gp = []\n",
    "\n",
    "    # Run the classifier on all tasks\n",
    "    for i in range(num_tasks):\n",
    "        y = int2bin(i, num_instances)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=RANDOM_STATE)\n",
    "        classifier.fit(x_train, y_train)\n",
    "        gp.append(classifier.score(x_test, y_test) - 0.5)  # The -0.5 gives performance rather than generalization accuracy\n",
    "\n",
    "    performances[name] = int(sum(gp))\n",
    "    \n",
    "print('Performances:')\n",
    "\n",
    "for name, performance in performances.items():\n",
    "    print(f'{name}: {performance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These were the algorithms I tested and the overall GP results from running my code:\n",
    "\n",
    "Dummy (most frequent strategy): <b style=\"color:red;\">0</b> <br>\n",
    "Naive Bayes: <b style=\"color:red;\">0</b> <br>\n",
    "MLP: <b style=\"color:red;\">0</b> <br>\n",
    "Decision Tree: <b style=\"color:red;\">0</b> <br>\n",
    "\n",
    "These results hold with NFL and what we were expected to see.  As a side note, I did not bother with tweaking any of the model hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('forex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2bc6dffc417b633bbbc31cedd954f3e10eebcdab1341647d4de83cb692948a0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
